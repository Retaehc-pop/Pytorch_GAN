{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name=\"anime-dcgan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import opendatasets as od\n",
    "# dataset_url = \"https://www.kaggle.com/splcher/animefacedataset\"\n",
    "# od.download(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "batch_size = 128\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) #normallize RGB to 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageFolder('./animefacedataset',transform=T.Compose([\n",
    "  T.Resize(image_size),#resize to 64x64\n",
    "  T.CenterCrop(image_size),#center crop to 64x64\n",
    "  T.ToTensor(),#convert to tensor\n",
    "  T.Normalize(*stats)]))#normalize to 0.5 from (0,1) to (-1,1)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(img_tensors):\n",
    "    \"\"\"take image_tensor multiply with standard deviation and add the mean value. Bring it back to (0,1)\"\"\"\n",
    "    return img_tensors * stats[1][0] + stats[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, nmax=64):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))\n",
    "\n",
    "def show_batch(dl, nmax=64):\n",
    "    for images, _ in dl:\n",
    "        show_images(images, nmax)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier model (DCGAN)\n",
    "import torch.nn as nn\n",
    "\n",
    "discriminator = nn.Sequential(\n",
    "    # input is 3 x 64 x 64\n",
    "    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # output is 64 x 32 x 32\n",
    "\n",
    "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # output is 128 x 16 x 16\n",
    "\n",
    "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # output is 256 x 8 x 8\n",
    "\n",
    "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # output is 512 x 4 x 4\n",
    "\n",
    "    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "    # output is 1 x 1 x 1\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Sigmoid()  # output is a probability\n",
    "    # classification use softmax, but generation use sigmoid\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    a = []\n",
    "    for item in x:\n",
    "        a.append(1/(1+math.exp(-item)))\n",
    "    return a\n",
    "\n",
    "\n",
    "x = np.arange(-10., 10., 0.2)\n",
    "sig = sigmoid(x)\n",
    "plt.plot(x, sig)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = to_device(discriminator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 128 # controller number, more latent more feature e.g. human face 1024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = nn.Sequential(\n",
    "  #input: latent_size x 1 x 1\n",
    "  nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "  nn.BatchNorm2d(512),\n",
    "  nn.ReLU(True),\n",
    "  #output: 512 x 4 x 4\n",
    "\n",
    "  nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "  nn.BatchNorm2d(256),\n",
    "  nn.ReLU(True),\n",
    "  #output: 256 x 8 x 8\n",
    "\n",
    "  nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "  nn.BatchNorm2d(128),\n",
    "  nn.ReLU(True),\n",
    "  #output: 128 x 16 x 16\n",
    "\n",
    "  nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "  nn.BatchNorm2d(64),\n",
    "  nn.ReLU(True),\n",
    "  #output: 64 x 32 x 32\n",
    "\n",
    "  nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "  nn.Tanh()\n",
    "  #output: 3 x 64 x 64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## value from (-1,1)\n",
    "def tanh(x):\n",
    "    a = []\n",
    "    for item in x:\n",
    "        a.append(math.tanh(item))\n",
    "    return a\n",
    "\n",
    "x = np.arange(-10., 10., 0.2)\n",
    "tan = tanh(x)\n",
    "plt.plot(x, tan)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random latent vector\n",
    "xb = torch.randn(batch_size, latent_size, 1, 1) # random latent tensors\n",
    "fake_images = generator(xb)\n",
    "print(fake_images.shape)\n",
    "show_images(fake_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = to_device(generator, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use binary crossentrophy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(real_images, opt_d):\n",
    "    # Clear discriminator gradients\n",
    "    opt_d.zero_grad()\n",
    "\n",
    "    # Pass real images through discriminator\n",
    "    real_preds = discriminator(real_images)\n",
    "    real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
    "    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
    "    real_score = torch.mean(real_preds).item()\n",
    "    \n",
    "    # Generate fake images\n",
    "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "    fake_images = generator(latent)\n",
    "\n",
    "    # Pass fake images through discriminator\n",
    "    fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n",
    "    fake_preds = discriminator(fake_images)\n",
    "    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
    "    fake_score = torch.mean(fake_preds).item()\n",
    "\n",
    "    # Update discriminator weights\n",
    "    loss = real_loss + fake_loss\n",
    "    loss.backward()\n",
    "    opt_d.step()\n",
    "    return loss.item(), real_score, fake_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(opt_g):\n",
    "    # Clear generator gradients\n",
    "    opt_g.zero_grad()\n",
    "    \n",
    "    # Generate fake images\n",
    "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "    fake_images = generator(latent)\n",
    "    \n",
    "    # Try to fool the discriminator\n",
    "    preds = discriminator(fake_images)\n",
    "    targets = torch.ones(batch_size, 1, device=device)\n",
    "    loss = F.binary_cross_entropy(preds, targets)\n",
    "    \n",
    "    # Update generator weights\n",
    "    loss.backward()\n",
    "    opt_g.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "import os\n",
    "sample_dir = \"generated\"\n",
    "os.makedirs(sample_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(index,latent_tensors,show=True):\n",
    "  fake_images = generator(latent_tensors)\n",
    "  fake_fname = 'generated-images-{:04d}.png'.format(index)\n",
    "  save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
    "  print('Saving', fake_fname)\n",
    "  if show:\n",
    "      fig, ax = plt.subplots(figsize=(8, 8))\n",
    "      ax.set_xticks([]); ax.set_yticks([])\n",
    "      ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_samples(0, fixed_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs,lr,start_idx=1):\n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "  #loss and score\n",
    "  losses_g = []\n",
    "  losses_d = []\n",
    "  real_scores = []\n",
    "  fake_scores = []\n",
    "\n",
    "  #Create Optimizers\n",
    "  opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "  opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    #Train generator and discriminator\n",
    "    for real_images, _ in tqdm(train_dl):\n",
    "      loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n",
    "      loss_g = train_generator(opt_g)\n",
    "    \n",
    "    #keep record and score\n",
    "    losses_g.append(loss_g)\n",
    "    losses_d.append(loss_d)\n",
    "    real_scores.append(real_score)\n",
    "    fake_scores.append(fake_score)\n",
    "\n",
    "    #log losses & scorees (last batch)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] Loss_D: {loss_d} Loss_G: {loss_g} Real_Score: {real_score} Fake_Score: {fake_score}\")\n",
    "\n",
    "    #save samples\n",
    "    save_samples(epoch+start_idx, fixed_latent)\n",
    "\n",
    "  return losses_g, losses_d, real_scores, fake_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fit(epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_g, losses_d, real_scores, fake_scores = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoints \n",
    "torch.save(generator.state_dict(), 'G.pth')\n",
    "torch.save(discriminator.state_dict(), 'D.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "vid_fname = 'gans_training.avi'\n",
    "\n",
    "files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'generated' in f]\n",
    "files.sort()\n",
    "\n",
    "out = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 1, (530,530))\n",
    "[out.write(cv2.imread(fname)) for fname in files]\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses_d, '-')\n",
    "plt.plot(losses_g, '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Discriminator', 'Generator'])\n",
    "plt.title('Losses');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('torch37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e6cef898c9b592b88ca17f2dd845c7b5cbc7c8460f9a2c9df2e7b948f1078ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
